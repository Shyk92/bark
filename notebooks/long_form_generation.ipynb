{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39ea4bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/nshykula/TTScocqui/.venv/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /Users/nshykula/TTScocqui/.venv/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/nshykula/TTScocqui/.venv/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/nshykula/TTScocqui/.venv/lib/python3.10/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /Users/nshykula/TTScocqui/.venv/lib/python3.10/site-packages (from nltk) (4.66.1)\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nshykula/TTScocqui/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "!python -m pip install nltk\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "from IPython.display import Audio\n",
    "import nltk  # we'll use this to split into sentences\n",
    "import numpy as np\n",
    "\n",
    "from bark.generation import (\n",
    "    generate_text_semantic,\n",
    "    preload_models,\n",
    ")\n",
    "from bark.api import semantic_to_waveform\n",
    "from bark import generate_audio, SAMPLE_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "776964b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nshykula/TTScocqui/.venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "preload_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d03f4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTORCH_ENAVLE_MPS_FALLBACK=1\n",
    "!export SUNO_MPS_ENABLE_CROSS_DEVICE=1\n",
    "!export SUNO_MPS_ENABLR=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a025a4",
   "metadata": {},
   "source": [
    "# Simple Long-Form Generation\n",
    "We split longer text into sentences using `nltk` and generate the sentences one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57b06e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "script = \"\"\"\n",
    "Hey, have you heard about this new text-to-audio model called \"Bark\"? \n",
    "Apparently, it's the most realistic and natural-sounding text-to-audio model \n",
    "out there right now. People are saying it sounds just like a real person speaking. \n",
    "I think it uses advanced machine learning algorithms to analyze and understand the \n",
    "nuances of human speech, and then replicates those nuances in its own speech output. \n",
    "It's pretty impressive, and I bet it could be used for things like audiobooks or podcasts. \n",
    "In fact, I heard that some publishers are already starting to use Bark to create audiobooks. \n",
    "It would be like having your own personal voiceover artist. I really think Bark is going to \n",
    "be a game-changer in the world of text-to-audio technology.\n",
    "\"\"\".replace(\"\\n\", \" \").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f747f804",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17400a9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 43.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:06<00:00,  2.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 22.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 33/33 [00:13<00:00,  2.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 66.30it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 20.99it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 35/35 [00:14<00:00,  2.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 25.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 29/29 [00:11<00:00,  2.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 23.90it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 30/30 [00:12<00:00,  2.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 53.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 14/14 [00:05<00:00,  2.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 50.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 15/15 [00:05<00:00,  2.57it/s]\n"
     ]
    }
   ],
   "source": [
    "SPEAKER = \"v2/en_speaker_6\"\n",
    "silence = np.zeros(int(0.25 * SAMPLE_RATE))  # quarter second of silence\n",
    "\n",
    "pieces = []\n",
    "for sentence in sentences:\n",
    "    audio_array = generate_audio(sentence, history_prompt=SPEAKER)\n",
    "    pieces += [audio_array, silence.copy()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cf77f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(np.concatenate(pieces), rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2d4625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d13249b",
   "metadata": {},
   "source": [
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfc8bf5",
   "metadata": {},
   "source": [
    "# Advanced Long-Form Generation\n",
    "Somtimes Bark will hallucinate a little extra audio at the end of the prompt.\n",
    "We can solve this issue by lowering the threshold for bark to stop generating text. \n",
    "We use the `min_eos_p` kwarg in `generate_text_semantic`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62807fd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/nshykula/TTScocqui/bark/notebooks/long_form_generation.ipynb Cell 12\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nshykula/TTScocqui/bark/notebooks/long_form_generation.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m silence \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mint\u001b[39m(\u001b[39m0.25\u001b[39m \u001b[39m*\u001b[39m SAMPLE_RATE))  \u001b[39m# quarter second of silence\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nshykula/TTScocqui/bark/notebooks/long_form_generation.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pieces \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nshykula/TTScocqui/bark/notebooks/long_form_generation.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m sentences:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nshykula/TTScocqui/bark/notebooks/long_form_generation.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     semantic_tokens \u001b[39m=\u001b[39m generate_text_semantic(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nshykula/TTScocqui/bark/notebooks/long_form_generation.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         sentence,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nshykula/TTScocqui/bark/notebooks/long_form_generation.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         history_prompt\u001b[39m=\u001b[39mSPEAKER,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nshykula/TTScocqui/bark/notebooks/long_form_generation.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         temp\u001b[39m=\u001b[39mGEN_TEMP,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nshykula/TTScocqui/bark/notebooks/long_form_generation.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         min_eos_p\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m,  \u001b[39m# this controls how likely the generation is to end\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nshykula/TTScocqui/bark/notebooks/long_form_generation.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nshykula/TTScocqui/bark/notebooks/long_form_generation.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     audio_array \u001b[39m=\u001b[39m semantic_to_waveform(semantic_tokens, history_prompt\u001b[39m=\u001b[39mSPEAKER,)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentences' is not defined"
     ]
    }
   ],
   "source": [
    "GEN_TEMP = 0.6\n",
    "SPEAKER = \"v2/en_speaker_6\"\n",
    "silence = np.zeros(int(0.25 * SAMPLE_RATE))  # quarter second of silence\n",
    "\n",
    "pieces = []\n",
    "for sentence in sentences:\n",
    "    semantic_tokens = generate_text_semantic(\n",
    "        sentence,\n",
    "        history_prompt=SPEAKER,\n",
    "        temp=GEN_TEMP,\n",
    "        min_eos_p=0.05,  # this controls how likely the generation is to end\n",
    "    )\n",
    "\n",
    "    audio_array = semantic_to_waveform(semantic_tokens, history_prompt=SPEAKER,)\n",
    "    pieces += [audio_array, silence.copy()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133fec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(np.concatenate(pieces), rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eee9f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be8e125e",
   "metadata": {},
   "source": [
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a16c1b",
   "metadata": {},
   "source": [
    "# Make a Long-Form Dialog with Bark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c5eff8",
   "metadata": {},
   "source": [
    "### Step 1: Format a script and speaker lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5238b297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Samantha:[EROTICA]mmmmmm, I want you inside me.',\n",
       " 'John:[EROTICA] you know Ill always give you what you want.',\n",
       " 'Samantha:[EROTICA]Thats why I love you.',\n",
       " 'John:[EROTICA]Come here, baby.',\n",
       " 'Samantha:[EROTICA]Yes, sir.',\n",
       " 'John:[EROTICA]Put your legs around me.',\n",
       " 'Samantha:[EROTICA]Like this?',\n",
       " 'John:[EROTICA]Perfect.',\n",
       " 'Samantha:[EROTICA]Oh, God.',\n",
       " 'John:[EROTICA]You feel so good.',\n",
       " 'Samantha:[EROTICA]Dont stop.[fucking].',\n",
       " 'John:[EROTICA]Never.',\n",
       " 'Samantha:[EROTICA] Were going to make such beautiful babies together.',\n",
       " 'John:[EROTICA]Thats our plan, sweetheart.',\n",
       " 'Samantha:[EROTICA]Oooohhhh...[SEX SFX].',\n",
       " 'John:[EROTICA]ugh, ugh, you like when I fuck that pussy dont you?',\n",
       " 'Samantha:[EROTICA]yes! yes! uuh, uh! my tight cunt loves yoour big dick!']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_lookup = {\"Samantha\": \"v2/en_speaker_9\", \"John\": \"v2/en_speaker_2\"}\n",
    "\n",
    "# Script generated by chat GPT\n",
    "script = f\"\"\"\n",
    "Samantha:[EROTICA]mmmmmm, I want you inside me.\n",
    "John:[EROTICA] you know Ill always give you what you want.\n",
    "Samantha:[EROTICA]Thats why I love you.\n",
    "John:[EROTICA]Come here, baby.\n",
    "Samantha:[EROTICA]Yes, sir.\n",
    "John:[EROTICA]Put your legs around me.\n",
    "Samantha:[EROTICA]Like this?\n",
    "John:[EROTICA]Perfect.\n",
    "Samantha:[EROTICA]Oh, God.\n",
    "John:[EROTICA]You feel so good.\n",
    "Samantha:[EROTICA]Dont stop.[fucking].\n",
    "John:[EROTICA]Never.\n",
    "Samantha:[EROTICA] Were going to make such beautiful babies together.\n",
    "John:[EROTICA]Thats our plan, sweetheart.\n",
    "Samantha:[EROTICA]Oooohhhh...[SEX SFX].\n",
    "John:[EROTICA]ugh, ugh, you like when I fuck that pussy dont you?\n",
    "Samantha:[EROTICA]yes! yes! uuh, uh! my tight cunt loves yoour big dick!\n",
    "\"\"\"\n",
    "script = script.strip().split(\"\\n\")\n",
    "script = [s.strip() for s in script if s]\n",
    "script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee547efd",
   "metadata": {},
   "source": [
    "### Step 2: Generate the audio for every speaker turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "203e5081",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/nshykula/TTScocqui/bark/notebooks/long_form_generation.ipynb Cell 20\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nshykula/TTScocqui/bark/notebooks/long_form_generation.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m script:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nshykula/TTScocqui/bark/notebooks/long_form_generation.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m line:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nshykula/TTScocqui/bark/notebooks/long_form_generation.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         speaker, text \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nshykula/TTScocqui/bark/notebooks/long_form_generation.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         pieces \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [generate_audio(text, history_prompt\u001b[39m=\u001b[39mspeaker_lookup[speaker]), silence\u001b[39m.\u001b[39mcopy()]\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "pieces = []\n",
    "silence = np.zeros(int(0.5*SAMPLE_RATE))\n",
    "for line in script:\n",
    "    if \":\" in line:\n",
    "        speaker, text = line.split(\": \")\n",
    "        pieces += [generate_audio(text, history_prompt=speaker_lookup[speaker]), silence.copy()]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c54bada",
   "metadata": {},
   "source": [
    "### Step 3: Concatenate all of the audio and play it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27a56842",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/nshykula/TTScocqui/bark/notebooks/long_form_generation.ipynb Cell 22\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nshykula/TTScocqui/bark/notebooks/long_form_generation.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m wavfile\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nshykula/TTScocqui/bark/notebooks/long_form_generation.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m Audio(np\u001b[39m.\u001b[39;49mconcatenate(pieces), rate\u001b[39m=\u001b[39mSAMPLE_RATE)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nshykula/TTScocqui/bark/notebooks/long_form_generation.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#wavfile.write(\"dialoguesex.wav\", SAMPLE_RATE, Audio)\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "from scipy.io import wavfile\n",
    "Audio(np.concatenate(pieces), rate=SAMPLE_RATE)\n",
    "#wavfile.write(\"dialoguesex.wav\", SAMPLE_RATE, Audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bc5877",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
